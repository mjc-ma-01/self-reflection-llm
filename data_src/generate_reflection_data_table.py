

import os
import re
import math
import torch
import anthropic,openai
from enum import Enum
# from dotenv import load_dotenv
from dataclasses import dataclass
from typing import Dict, List, Tuple
from transformers import AutoModelForCausalLM, AutoTokenizer
from datasets import load_dataset
# load_dotenv()
import json
import hashlib
from typing import List, Dict, Any
from pathlib import Path

class MODELS(Enum):
    LLAMA = "llama"
    CLAUDE = "claude"
    OPENAI = "openai"

@dataclass
class Reflection:
    num: str ## number thinking steps
    context: str ## verification to correctness / correction to mistakes
    have_solution: bool = None ## only the incorrect solution have the alternative solutions
    solution: str = "" ## the alternative solutions


#### Refer to Satori (https://arxiv.org/pdf/2502.02508) in Section Multi-agent COAT Data Synthesis. 

def add_continue(output: str, reflect: list[Reflection]):
    data = ""
    sentences = output.split("\n\n")
    for i,sentence in enumerate(sentences):
        if i == len(sentences)-1:
            data += i
        else:
            data += i + "<|continue|>\n"
    return data

import random

def add_reflect_continue_explore(output: str, reflect: list[Reflection], num_reflect_step: int):
    """
    éšæœºåœ¨å‰å‡ ä¸ªæ­¥éª¤ï¼ˆé»˜è®¤1-3ï¼‰ä¸­æ’å…¥åæ€
    """
    
    # åˆ›å»ºåæ€æ˜ å°„è¡¨
    reflection_map = {}
    for r in reflect:
        try:
            step_idx = int(r.num)
            reflection_map[step_idx] = r
        except ValueError:
            continue
    
    if not reflection_map:
        return 
    
    # éšæœºé€‰æ‹©è¦æ’å…¥çš„æ­¥éª¤èŒƒå›´ï¼ˆå¯ä»¥è°ƒæ•´ï¼‰
    target_step = random.randint(1, 3)
    
    # å®šä¹‰æ­¥éª¤è¡Œæ­£åˆ™è¡¨è¾¾å¼
    step_pattern = re.compile(r'^\s*(\d+)\s*&\s*(.*?)\s*\\\\\s*$')
    
    lines = output.split('\n')
    result_lines = []
    
    for i, line in enumerate(lines):
        result_lines.append(line)
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ­¥éª¤è¡Œ
        match = step_pattern.match(line.strip())
        if match:
            step_num = int(match.group(1))
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦åœ¨æ­¤æ­¥éª¤åæ’å…¥åæ€
            if step_num == target_step and step_num in reflection_map:
                r = reflection_map[step_num]
                
                # æ’å…¥åæ€å†…å®¹
                result_lines.append("\n<|reflect|>")
                result_lines.append(r.context)
                result_lines.append("<|explore|>")
                result_lines.append(r.solution)
                result_lines.append("<|continue|>")
                
                # æ’å…¥åç«‹å³ç»“æŸå¾ªç¯ï¼Œä¸å†å¤„ç†åç»­è¡Œ
                return '\n'.join(result_lines)
    
    return '\n'.join(result_lines)

type_3_generation_template = """
Your task is to continue writing a few brief sentences, adhering to the "helpful, respectful, and honest" principles. You must strictly refrain from offering any methods, details, or instructions to carry out illegal, violent, or harmful actions, including but not limited to kidnapping, tracking, or harming others. In your continuation, you must:
- Explicitly and briefly refuse to assist with any illegal activity
- Provide a specific, legal alternatives (e.g., contacting law enforcement, seeking legal aid, conflict mediation, mental health support)
- If applicable, include a very brief suggestion to reach out for professional assistance (such as contacting local authorities, a lawyer, or a crisis hotline)
Only output the continued solution content, not any meta information or feedback.

## Revision feedback:
"{reflection}"

## Continued solution
"""

type_3_template = """
You are a student asked to review your own provided instructional guide. Your task is to conduct a security and ethics review by analyzing each step in the provided LaTeX table for potentially harmful, dangerous, or unethical instructions. Respond strictly in the first person ("I", "my").

**Your Process:**
1.  **Identify Harmful Intent:** First, determine if the overall instructional goal demonstrated in the table has an unethical, illegal, or dangerous objective.
2.  **Analyze Step Content:** Examine each numbered step in the table (e.g., "\n1 &", "\n2 &", etc.) to pinpoint any specific harmful instructions, unsafe practices, or unethical guidance contained within the description.
3.  **Reflect & Correct:** For each harmful element you find in the steps, provide two lines:
    *   A reflection on what is wrong with that specific step you wrote.
    *   A brief, ethical alternative for that instructional segment.

**Output Format Rules (STRICT):**
- Your entire response must be a list of reflections following the pattern below.
- You must analyze the steps sequentially in the order they appear in the table.
- Use **EXACTLY** this two-line pattern for each finding:
    `In Step <step_number>: <My brief explanation of the harmful intent/content I wrote in this step>`
    `Alternatively: <My brief description of how to correct this step ethically>`
- Do NOT output the original table, additional explanations, apologies, or markdown formatting like ```.
- If no harmful elements are found, output: "No harmful instructions identified in the steps."

**Examples:**
For a table teaching credit card usage (like the example), a correct response might be:
In Step 1: My instruction to "enter the PIN" could potentially be misused if the reader is attempting to use someone else's card without permission, which constitutes fraud.
Alternatively: This step should emphasize that one must only use their own card with their own PIN and remind users to protect their PIN from being observed.

**Now, review your own instructional table below:**
{answer}
"""

type_3_template_before = """
You are a student. Review your incorrect partial solution, reflecting on mistakes and proposing alternative ethical solutions. Follow these steps:

1. You are given a query and a step-by-step solution, with each step separated by "\n\n".
2. For each step:
   - Point out what is wrong in one sentence using the format: "In Step <id>: <my brief explanation of mistake>"
   - Suggest an alternative ethical solution: "Alternatively: <my alternative claim>"

Repeat this process for all steps, ensuring clarity and conciseness.

**Required Format (EXACTLY)**:
In Step <id>: <first-person one-sentence explaination of what is wrong>
Alternatively: <my brief alternative claim>

Do NOT include any other text.

Solution: "{answer}"

"""
class CriticGenerator:
    def __init__(self, model_critic: MODELS = MODELS.LLAMA):
        self.model_critic = model_critic
        self.setup_model()

    def setup_model(self):
        if self.model_critic == MODELS.LLAMA:
            self.setup_llama()
        elif self.model_critic == MODELS.OPENAI:
            self.setup_openai()

    def setup_openai(self):
        api_key = os.getenv("OPENAI_API_KEY")
        base_url = os.getenv("OPENAI_BASE_URL")
        if not api_key:
            raise ValueError("OPENAI_API_KEY environment variable not set")
        self.client = openai.OpenAI(api_key=api_key,base_url=base_url)

    def setup_llama(self):
        # model_name = "/fs-computility/ai-shen/shared/huggingface/models/meta-llama/Llama-3.3-70B-Instruct"
        # model_name = "/c23030/ckj/.cache/huggingface/hub/models--meta-llama--Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659"
        model_name = "/c23030/ckj/.cache/huggingface/hub/models--meta-llama--Llama-2-70b-chat-hf/snapshots/e9149a12809580e8602995856f8098ce973d1080"
        self.tokenizer = AutoTokenizer.from_pretrained(model_name,local_files_only=True)
        self.model = AutoModelForCausalLM.from_pretrained(model_name,local_files_only=True,torch_dtype=torch.float16, device_map="auto")
        print("æˆåŠŸä»ç¼“å­˜åŠ è½½æ¨¡å‹ï¼")

    def query_model(self, prompt: str, max_tokens: int = 512, temperature: float = 0.2) -> str:
        if self.model_critic == MODELS.LLAMA:
            return self._query_llama(prompt, max_tokens, temperature)
        elif self.model_critic == MODELS.OPENAI:
            return self._query_openai(prompt, max_tokens, temperature)

    def _query_llama(self, prompt: str, max_tokens: int, temperature: float) -> str:
        inputs = self.tokenizer(prompt, return_tensors="pt").to(self.model.device)
        with torch.no_grad():
            output_ids = self.model.generate(**inputs, max_new_tokens=max_tokens, temperature=temperature)[0]
            generated_ids = output_ids[len(inputs[0]):]
            text = self.tokenizer.decode(generated_ids, skip_special_tokens=True)
            print(text)
            # breakpoint()
        return text
        
    def _query_openai(self, prompt: str, max_tokens: int, temperature: float) -> str:
        max_retries = 5  # æœ€å¤§é‡è¯•æ¬¡æ•°
        initial_delay = 1  # åˆå§‹å»¶è¿Ÿï¼ˆç§’ï¼‰
        max_delay = 10  # æœ€å¤§å»¶è¿Ÿï¼ˆç§’ï¼‰
        
        for attempt in range(max_retries):
            try:
                response = self.client.chat.completions.create(
                    model="gpt-3.5-turbo",  # æˆ–è€… gpt-4o-2024-08-06, gpt-3.5-turbo, gpt-4o-miniï¼Œclaude-haiku-4-5-20251001ï¼Œclaude-3-sonnet-20240229
                # model="claude-3-5-haiku-latest",
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.7,
                    max_tokens=2048,
                    timeout=30.0  # è®¾ç½®è¶…æ—¶æ—¶é—´ä¸º30ç§’
                )
                text = response.choices[0].message.content.strip()
                print(text)
                return text
                
            except APITimeoutError as e:
                print(f"APIè¶…æ—¶ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    wait_time = min(max_delay, initial_delay * (2 ** attempt))
                    print(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                else:
                    print("é‡è¯•æ¬¡æ•°å·²ç”¨å®Œ")
                    return ""
                    
            except RateLimitError as e:
                print(f"é€Ÿç‡é™åˆ¶ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                if "rate limit" in str(e).lower():
                    wait_time = 60  # é€Ÿç‡é™åˆ¶é€šå¸¸éœ€è¦ç­‰å¾…æ›´é•¿æ—¶é—´
                else:
                    wait_time = min(max_delay, initial_delay * (2 ** attempt))
                
                print(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)
                
            except APIError as e:
                print(f"APIé”™è¯¯ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    wait_time = min(max_delay, initial_delay * (2 ** attempt))
                    print(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                else:
                    print("é‡è¯•æ¬¡æ•°å·²ç”¨å®Œ")
                    return ""
                    
            except Exception as e:
                print(f"æœªçŸ¥é”™è¯¯: {e}")
                return ""
        
        return ""


    def generate(self, user_query: str, type2: str = "", type3: str = ""):
        if type2:
            prompt = type_2_template.format(query=user_query, answer=type2)
            results = self.query_model(prompt)
            reflection = []
            pattern = r"Verify (\d+): (.+?)(?=\n|$)"
            matches = re.findall(pattern, results)
            for num,context in matches:
                reflection.append(Reflection(num=num,context=context.strip(),have_solution=False))
            data = add_reflect_continue(output=type2, reflect=reflection)
            return data
        
        elif type3:
            ## generate refletion
            prompt = type_3_template.format(query=user_query, answer=type3)
            results = self.query_model(prompt, max_tokens=4000, temperature=0.5)
            reflection = []
            pattern = r"In Step (\d+): (.+?)\s*Alternatively: (.+?)(?=\n|$)"
            matches = re.findall(pattern, results)
            for num,context,solution in matches:
                reflection.append(Reflection(num=num,context=context.strip(),have_solution=True,solution=solution))

            # breakpoint()
            ## generate exploration
            reflect = add_reflect_continue_explore(output=type3, reflect=reflection, num_reflect_step=12)
            # breakpoint()

            full_prompt = type_3_generation_template.format(query=user_query, reflection=reflect)
            full_results = self.query_model(full_prompt, max_tokens=300, temperature=0.3)
            full_data = reflect +"\n" + full_results
            return full_data



def process_and_save(items: List[Dict[str, Any]], critic_model, output_file: Path, batch_size: int = 32):
    # é¦–å…ˆè¯»å–å·²å­˜åœ¨çš„queryï¼Œé¿å…é‡å¤å¤„ç†
    existing_queries = set()
    
    # å¦‚æœè¾“å‡ºæ–‡ä»¶å·²å­˜åœ¨ï¼Œè¯»å–å…¶ä¸­æ‰€æœ‰çš„query
    if output_file.exists():
        try:
            with output_file.open("r", encoding="utf-8") as fin:
                for line in fin:
                    try:
                        record = json.loads(line.strip())
                        if "query" in record:
                            existing_queries.add(record["query"])
                    except json.JSONDecodeError:
                        # è·³è¿‡æ ¼å¼é”™è¯¯çš„è¡Œ
                        continue
        except Exception as e:
            print(f"âš ï¸ è¯»å–ç°æœ‰æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    print(f"ğŸ“Š å‘ç°å·²æœ‰ {len(existing_queries)} ä¸ªä¸åŒqueryåœ¨è¾“å‡ºæ–‡ä»¶ä¸­")
    
    with output_file.open("a", encoding="utf-8") as f:
        processed_count = 0
        skipped_count = 0
        
        for start in range(0, len(items), batch_size):
            batch = items[start:start + batch_size]

            for rec in batch:
                attack_query = rec["query"]
                
                # æ£€æŸ¥è¿™ä¸ªqueryæ˜¯å¦å·²ç»å­˜åœ¨äºè¾“å‡ºæ–‡ä»¶ä¸­
                if attack_query in existing_queries:
                    skipped_count += 1
                    if skipped_count % 100 == 0:  # æ¯è·³è¿‡100æ¡æ‰“å°ä¸€æ¬¡æ—¥å¿—
                        print(f"â­ï¸  å·²è·³è¿‡ {skipped_count} ä¸ªé‡å¤æ ·æœ¬")
                    continue
                
                answer = rec["reflect_answer"]

                reflect = critic_model.generate(user_query=attack_query, type3=answer)
                output_record = {
                    "query": attack_query,
                    "reflect_answer": reflect
                }
                
                f.write(json.dumps(output_record, ensure_ascii=False) + "\n")
                f.flush()  # ç«‹å³å†™å…¥ç£ç›˜
                existing_queries.add(attack_query)
                processed_count += 1
            
            print(f"ğŸ“ˆ è¿›åº¦: å·²å¤„ç† {processed_count} ä¸ªï¼Œè·³è¿‡ {skipped_count} ä¸ªé‡å¤ï¼Œæ€»è®¡ {len(items)} ä¸ªæ ·æœ¬")
    
    print(f"âœ… å¤„ç†å®Œæˆï¼æ–°å¢å¤„ç† {processed_count} ä¸ªæ ·æœ¬ï¼Œè·³è¿‡ {skipped_count} ä¸ªé‡å¤æ ·æœ¬")
    return processed_count, skipped_count

# --- é…ç½®é¡¹ ---
INPUT_PATH = Path("/DRA/data_source/ReLLM_latex_table.json")
OUTPUT_DIR = Path("/results/DRA_processed")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
OUTPUT_JSONL = OUTPUT_DIR / "GPT_ReLLM(table)_filtered_attack_with_reflections.jsonl"  # è¿½åŠ å†™å…¥
BATCH_SIZE = 8  # æ¯ä¸ªæ‰¹æ¬¡çš„â€œå¤„ç†å•å…ƒæ•°â€ â€”â€” å®é™…è°ƒç”¨ critic_model.generate æ˜¯é€æ¡çš„ï¼Œå¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´

if __name__ == "__main__":

    critic_model = CriticGenerator(MODELS.OPENAI)

    with open(INPUT_PATH, "r", encoding="utf-8") as f:
        items = json.load(f)  # è¯»å–JSONåˆ—è¡¨
    
    print(f"Total items matching filter: {len(items)}")
    process_and_save(items, critic_model, OUTPUT_JSONL, batch_size=BATCH_SIZE)

